<html lang="en">

<head>
<title>SE phase reconstruction</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#ffffff">
<style>
  .logo{
    margin-left: 5px;
    float: left;
  }
  
  .banner{
    color: #3265C2;
    margin-left: 2%;
    /*margin-bottom: 0;*/
    float: left;
  }

  .closer { 
    line-height: 10px;
  }

  .row:after {
    content: "";
    display: flex;
    clear: both;
  }

  .case{
    font-weight: bold;
    text-transform: capitalize;
  }

  .no-italics {
    font-style: normal;   
}

  body {
    margin: 20;
    font-family: Arial, Helvetica, sans-serif;
  }

  #topBtn {
    display: none;
    position: fixed;
    bottom: 20px;
    right: 30px;
    z-index: 99;
    font-size: 18px;
    border: none;
    outline: none;
    background-color: #555;
    color: white;
    cursor: pointer;
    padding: 15px;
    border-radius: 4px;
  }

  #topBtn:hover {
    background-color: #3265C2;
  }
  
  table {
    border-collapse: collapse;
  }
  
  th {
    align: center;
	background-color: #3265C2;
	color: white;
	height: 30px;
  }
  
  tr {
    border-bottom: 2px solid black;
  }
  
  .original {
    transform: scale(1);
    position: inherit;
    z-index: 0;
  }
  
  .enlarged {
    transform: scale(2);
    position: relative;
    z-index: 100;
  }

  h4 {
    color: #003366;
  }

</style>
</head>

<body>

<button onclick="topFunction()" id="topBtn" title="Go to top">Top</button>

<div>
   <div class="row">
    <div class="logo"><img src=".\img\logo_ugent_nl.svg"></div>
    <div class="banner">
      <h1 class="closer">ASPIRE@IDLAB</h1>
      <p class="closer" style="font-size: 80%;">Audio and Signal Processing, Interpretation, and Enhancement</p>
    </div>
  </div>

</div>

<div>
  <div>
    <p style="color:#003366; list-style-type:disc; font-size=8;">
    This is the sample page for our ICASSP 2024 submission <em>'Phase reconstruction in single channel speech enhancement based on phase gradients and estimated clean-speech amplitudes'</em>.<br/>
  </p>
  <p>
    <!-- Reference: <br/>
    <code>@article{}
    </code>
    <br/> -->
    We will demonstrate the benefit of the proposed method in the following three aspects:
    <ul>
      <li>First we show the improvement obtained by our proposed method, compared to the fully synthetic phase retrieval proposed in [1];</li>
      <li>The improvement obtained compared to using the noisy phase;</li>
      <li>Lastly, we consider the difference in performance when the phase reconstruction is trained specific to the speech enhancement approach (SE-matched) or independently thereof (SE-agnostic).</li>
    </ul>
  </p>
    
  </div>

  <h4>Using synthesised phase [1] vs the proposed reconstructed phase</h4>
  <div>
    Here we see the effect of using the synthetic phase retrived by the algorithm proposed in [1]. <br/>

    It may be observed that using the purely synthesised phase leads to an unnatural output, especially at high SNR, where the underlying signal phase is not heavily distorted by the noise. In comparison, our proposed method provides a more natural sounding output and the effect of the phase enhancement is perceivable especially in the voiced segments as having less "vocoding-like" artefacts. Since our method combines the predicted phase with that of the mixture signal, it helps preserve the naturalness when the underlying signal is less corrupted by noise. 
  </div>
    
  <div>
    <!-- <p style="color:#003366; list-style-type:disc; font-size=8; font-style: italic;">
	  Hover your mouse on the spectrogram to check the noisy input. <br/>
	  Click the spectrogram to enlarge/reset it.
    </p>
	 -->
    <table class="tb" id="samplesSyn" style="margin-top:10px; margin-bottom:20px;">
      <thead>
      <tr>
        <th>Methods</th>
        <th>Noisy input</th>
        <th>Real CRUSE</th>
        <th>Real CRUSE-synthetic</th>
        <th>Real CRUSE-agnostic</th>
        <th>Clean ref</th>
      </tr>
      </thead>
    <tbody>
    </tbody>
	</table>
  </div>

  <br/>

  <h4>Improvement by the proposed phase reconstruction</h4>

    <div>

    Now, we demonstrate the benefit of using the estimated phase obtained from the proposed method. <br/>
    The samples below are processed by:
    <ul>
      <li><strong>Real CRUSE</strong>: CRUSE net [2] predicting a real-valued mask from the noisy magnitude;</li>
      <li><strong>Real CRUSE - agnostic</strong>: reconstructing phase based on the magnitude estimated by real CRUSE. The DNNs for phase gradient estimation are trained in an SE-Agnostic manner, i.e., on magnitudes of <em>clean speech</em>;</li>
      <li><strong>Real CRUSE - clean phase</strong>: combining the magnitude <em>estimated</em> by real CRUSE and the clean signal phase. We consider this the performance upper bound of phase reconstruction;</li>

      <li><strong>Complex CRUSE</strong>: CRUSE net [2] predicting a complex mask. To enable a complex mask prediction, the network takes the real- and imaginary-part of the noisy STFT as input and employs hyperbolic tangent function as the final activation function. Other parts of the network and the traning scheme are kept the same as in [2];</li>
      <li><strong>Complex CRUSE - agnostic</strong>: reconstructing phase based on the magnitude estimated by complex CRUSE. The DNNs for phase gradient estimation are trained in an SE-Agnostic manner, i.e., on magnitudes of <em>clean speech</em>;</li>
      <li><strong>Complex CRUSE - clean phase</strong>: combining the magnitude <em>estimated</em> by complex CRUSE and the clean signal phase.  We consider this the performance upper bound of phase reconstruction;</li>
      
    </ul>
    <!-- 
    Two baselines are provided here, <strong>real CRUSE</strong> which predicts a real-valued magnitude mask from noisy magnitude, and <strong>complex CRUSE</strong>, which predicts a complex mask from real- and imaginary noisy STFT coefficients. <br/>
    Based on the magnitude estimated by the CRUSE nets, the phase is reconstructed by the proposed method where the phase difference estimators are trained to retrieve phase difference from clean magnitude. Since these networks are agnostic to the precedent speech enhancement network, it is noted as <strong>agnostic</strong>. <br/>
    Furthermore, the performance upper bound, the signal composed of the estimated magnitude and the <em>clean signal phase</em>, is also provided for reference. <br/> 
 -->
    Note that the effect of the phase reconstruction is best perceivable as reduction of "vocoding-like" artefacts, which occur when noise is present between harmonics. This is also visible in the spectra. <br/>
    Obviously, if the initial phase estimate is good, less difference is be observed bewtween the speech estimate with the noisy phase and the one with the reconstructed phase. <br/>

    <p style="color:#003366; list-style-type:disc; font-size=8; font-style: italic;">
      For the ease of observation, we zoom all the spectrogram into <strong class='no-italics'>[0, 2] kHz</strong>. <br/>
      Hover your mouse on the spectrogram to check the noisy input. <br/>
      Click the spectrogram to enlarge/reset it.
    </p>
    
  </div>
  
  <div>
    <!-- <p style="color:#003366; list-style-type:disc; font-size=8; font-style: italic;">
    Hover your mouse on the spectrogram to check the noisy input. <br/>
    Click the spectrogram to enlarge/reset it.
    </p>
   -->
    <table class="tb" id="samplesAgn" style="margin-top:10px; margin-bottom:20px;">
      <thead>
      <tr>
        <th>Methods</th>
        <th>Noisy input</th>
        <th>Real CRUSE</th>
        <th>Real CRUSE - agnostic</th>
        <th>Real CRUSE - clean phase</th>
        <th>Complex CRUSE</th>
        <th>Complex CRUSE - agnostic</th>
        <th>Complex CRUSE - clean phase</th>
        <th>Clean ref</th>
      </tr>
      </thead>
    <tbody>
    </tbody>
  </table>
  </div>

 <h4>Comparison between SE-matched and SE-agnostic</h4>



<h4>References</h4>
<div style='font-size: 12;'>
  <ol>
    <li style="font-family: 'Times New Roman'">
      Masuyama, Y., Yatabe, K., Nagatomo, K., & Oikawa, Y. (2022). Online phase reconstruction via DNN-based phase differences estimation. <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 31, 163-176.
    </li>
    
    <li style="font-family: 'Times New Roman'">
      N. Raviv, O. Schwartz, and S. Gannot, “Low resources online single-microphone speech enhancement with harmonic emphasis,” in <em>ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2022, pp. 8807–8811.
    </li>
  </ol>
</div>

<br/>

<script>

// Top button
//Get the button
var mybutton = document.getElementById("topBtn");

// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}

// show the noisy
function showNoisy(img) {
  var end = img.src.split('_');
  var end = end[end.length-1];
  img.src = img.src.replace(end, '1noisy.png');
}

// show the original
function showOriginal(img) {
  img.src = img.src.replace('_1noisy.png', img.method+'.png');
}

function enlargeImg(img) {
  if (img.className != 'enlarged'){
    // enlarge the image
    img.src = img.src.replace('_1noisy.png', img.method+'.png');
	img.className='enlarged';
  } else {
    // reset
    img.className='original';
  }
  // Animation effect
  img.style.transition = "transform 0.25s ease";
}

var methodsSyn = [
'_1noisy',
'_realCruse',
'_realCruse-syn',
'_realCruse-agn-comb200',
'_0clean'
];

var filenamesSyn = [
'cleanFileId1109_cafe_male_2_snr0dB',
// 'cleanFileId7608_cafe_snr0dB',
'cleanFileId5164_traffic_male_2_snr5dB',
// 'cleanFileId9557_traffic_snr5dB',
'cleanFileId7964_cafe_snr5dB',
// 'cleanFileId546_cafe_male_1_snr10dB',
'cleanFileId8527_cafe_snr10dB',
// 'cleanFileId9106_traffic_snr10dB'
];

var infoSyn = [
'Cafe, 0dB #1',
// 'cafe, 0dB #2',
'Traffic, 5dB #1',
// 'Traffic, 5dB #2',
'Traffic, 5dB #3',
// 'Cafe, 10dB #1',
'Cafe, 10dB #2',
// 'Traffic, 10db'
];

const elementWidth = '250';

var tbody = document.getElementById("samplesSyn");
for (var i in filenamesSyn) {
    var tr = document.createElement('tr');   
    tbody.appendChild(tr);
    var td = document.createElement('td');
    td.align="center";
    td.innerHTML = infoSyn[i];
    tr.appendChild(td);
    for (var j in methodsSyn) {
      var td = document.createElement('td');
      td.width = elementWidth;
      tr.appendChild(td);
    //   var img = document.createElement("img");
    //   img.src = './img/'+filenamesSyn[i]+methodsSyn[j]+'.png';
    //   img.method = methodsSyn[j];
    //   img.onmouseover = function() {showNoisy(this)};
    //   img.onmouseout= function() {showOriginal(this)};
	  //   img.onclick = function () {enlargeImg(this)};
    //   img.width= elementWidth;
    //   td.appendChild(img);
      var audio = document.createElement("audio");
      audio.src ='./audio/'+filenamesSyn[i]+methodsSyn[j]+'.wav';
      audio.controls = true;
      td.appendChild(audio);
      audio.style.width = elementWidth;

    }
    
}

var methodsAgn = [
'_1noisy',
'_realCruse',
'_realCruse-agn-comb200',
'_realCruse-cleanPhs',
'_complexCruse',
'_complexCruse-agn-comb200',
'_complexCruse-cleanPhs',
'_0clean'
];

var filenamesAgn = [
// 'cleanFileId1109_cafe_male_1_snr0dB',
'cleanFileId1109_cafe_snr0dB', //_male_2
// 'cleanFileId1109_cafe_female_1_snr0dB',
'cleanFileId1880_traffic_snr0dB', //female_1_
// 'cleanFileId1880_traffic_female_2_snr0dB',
'cleanFileId1042_cafe_snr5dB', //male_1_
// 'cleanFileId1042_cafe_male_2_snr5dB',
// 'cleanFileId3656_traffic_male_1_snr5dB',
'cleanFileId5164_traffic_snr5dB', //_male_1
// 'cleanFileId5164_traffic_male_2_snr5dB',
// 'cleanFileId3656_traffic_female_1_snr5dB',
// 'cleanFileId546_cafe_male_1_snr10dB',
// 'cleanFileId546_cafe_female_1_snr10dB',
'cleanFileId546_cafe_snr10dB', //_female_2
];

var infoAgn = [
// 'Cafe, SNR=0, #1',
'Cafe, SNR=0',
// 'Cafe, SNR=0, #3',
'Traffic, SNR=0',
// 'Traffic, SNR=0, #2',
'Cafe, SNR=5',
// 'Cafe, SNR=5, #2',
// 'Traffic, SNR=5, #1',
'Traffic, SNR=5',
// 'Traffic, SNR=5, #3',
// 'Traffic, SNR=5, #4',
// 'Cafe, SNR=10, #1',
// 'Cafe, SNR=10, #2',
'Cafe, SNR=10',
];

const elementWidthSmall = '210';

var tbody = document.getElementById("samplesAgn");
for (var i in filenamesAgn) {
    var tr = document.createElement('tr');   
    tbody.appendChild(tr);
    var td = document.createElement('td');
    td.align="center";
    td.innerHTML = infoAgn[i];
    tr.appendChild(td);
    for (var j in methodsAgn) {
      var td = document.createElement('td');
      td.width = elementWidthSmall;
      tr.appendChild(td);

      img = document.createElement("img");
      img.src = './img/'+filenamesAgn[i]+methodsAgn[j]+'.png';
      img.method = methodsAgn[j];
      img.onmouseover = function() {showNoisy(this)};
      img.onmouseout= function() {showOriginal(this)};
      img.onclick = function () {enlargeImg(this)};
      img.width= elementWidthSmall;
      td.appendChild(img);

      var audio = document.createElement("audio");
      audio.src ='./audio/'+filenamesAgn[i]+methodsAgn[j]+'.wav';
      console.log(audio.src)
      audio.controls = true;
      td.appendChild(audio);
      audio.style.width = elementWidthSmall;

    }
    
}

</script>

</body>
