<html lang="en">

<head>
<title>SE phase reconstruction</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#ffffff">
<style>
  .logo{
    margin-left: 5px;
    float: left;
  }
  
  .banner{
    color: #3265C2;
    margin-left: 2%;
    /*margin-bottom: 0;*/
    float: left;
  }

  .closer { 
    line-height: 10px;
  }

  .row:after {
    content: "";
    display: flex;
    clear: both;
  }

  .case{
    font-weight: bold;
    text-transform: capitalize;
  }

  .no-italics {
    font-style: normal;   
}

  body {
    margin: 20;
    font-family: Arial, Helvetica, sans-serif;
  }

  #topBtn {
    display: none;
    position: fixed;
    bottom: 20px;
    right: 30px;
    z-index: 99;
    font-size: 18px;
    border: none;
    outline: none;
    background-color: #555;
    color: white;
    cursor: pointer;
    padding: 15px;
    border-radius: 4px;
  }

  #topBtn:hover {
    background-color: #3265C2;
  }
  
  table {
    border-collapse: collapse;
    display:block;
    margin-top:10px; 
    margin-bottom:20px;
  }
  
  th {
    align: center;
	  position: sticky;
    top: 0;
    background-color: white;
  	color: #3265C2;
  	height: 30px;
  }
  
  tr {
    border-bottom: 2px solid black;
  }

  #managerTable {
    max-height: 500px;
    overflow: auto;
}

  .data-column {
      align: center;
      width: 150px;
      text-align: center;
  }
  
  .original {
    transform: scale(1);
    position: inherit;
    z-index: 0;
  }
  
  .enlarged {
    transform: scale(2);
    position: relative;
    z-index: 100;
  }

  h4 {
    color: #003366;
  }

</style>
</head>

<body>

<button onclick="topFunction()" id="topBtn" title="Go to top">Top</button>

<div>
   <div class="row">
    <div class="logo"><img src=".\img\logo_ugent_nl.svg"></div>
    <div class="banner">
      <h1 class="closer">ASPIRE@IDLAB</h1>
      <p class="closer" style="font-size: 80%;">Audio and Signal Processing, Interpretation, and Enhancement</p>
    </div>
  </div>

</div>

<div>
  <div>
    <p style="color:#003366; list-style-type:disc; font-size=8;">
    This is the sample page for our ICASSP 2024 submission <em>'Phase reconstruction in single channel speech enhancement based on phase gradients and estimated clean-speech amplitudes'</em>.<br/>
  </p>

<!--     <h3>Extra evaluation</h4>

<p>
    The reviewer suggested us to compare our method with other methods such as [a] and [d] on the Voiceband-Demand dataset.
    We conducted a brief evaluation of the proposed agnostic methods on the complex CRUSE (Complex CRUSE-agn) and report the results here in response to this requests. The last four systems in the table are reported by [a], including time-frequency domain methods [a,b,d] and time-domain method [c]. 
  </p>
  <div>
    <table>
      <thead>
      <tr>
        <th style="width: 200px;">Methods</th>
        <th class="data-column">Csig</th>
        <th class="data-column">Cbak</th>
        <th class="data-column">Covl</th>
      </tr>
      </thead>
    <tbody>
      <tr>
        <td>Noisy</td>
        <td class="data-column">3.59</td>
        <td class="data-column">3.00</td>
        <td class="data-column">2.92</td>
      </tr>
      <!-- <tr>
        <td>Complex-CRUSE</td>
        <td class="data-column">4.16</td>
        <td class="data-column">3.65</td>
        <td class="data-column">3.58</td>
      </tr> 
      <tr>
        <td>Complex-CRUSE-Agn</td>
        <td class="data-column" style="font-weight:bold">4.50</td>
        <td class="data-column" style="font-weight:bold">4.05</td>
        <td class="data-column" style="font-weight:bold">3.95</td>
      </tr>
	  
      <tr style="border-bottom:2px solid black">
        <td colspan="100%"></td>
      </tr>

      <tr>
        <td>PHASEN [a]</td>
        <td class="data-column">4.21</td>
        <td class="data-column">3.55</td>
        <td class="data-column">3.62</td>
      </tr>
      <tr>
        <td>T-GSA [b]</td>
        <td class="data-column">4.18</td>
        <td class="data-column">3.59</td>
        <td class="data-column">3.62</td>
      </tr>
      <tr>
        <td>TSTNN [c]</td>
        <td class="data-column">4.17</td>
        <td class="data-column">3.53</td>
        <td class="data-column">3.49</td>
      </tr>
      <tr>
        <td>FRNet [d]</td>
        <td class="data-column">4.32</td>
        <td class="data-column">3.53</td>
        <td class="data-column">3.68</td>
      </tr>
      
    </tbody>
  </table>
  </div>

  <h4>Baselines</h4>
  <div style='font-size: 12;'>
    <ol  type="a">
      <li style="font-family: 'Times New Roman'">
        Li, A., Zheng, C., Yu, G., Cai, J., & Li, X. "Filtering and refining: A collaborative-style framework for single-channel speech enhancement." <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, (2022) 30, 2156-2172.
      </li>

      <li style="font-family: 'Times New Roman'">
        Yin, D., Luo, C., Xiong, Z., & Zeng, W. PHASEN: A phase-and-harmonics-aware speech enhancement network. <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>. 2020, Vol. 34, No. 05, pp. 9458-9465.
      </li>

      <li style="font-family: 'Times New Roman'">
        Kim, J., El-Khamy, M., & Lee, J. T-GSA: Transformer with gaussian-weighted self-attention for speech enhancement. <em>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing</em>. IEEE, 2020, pp. 6649-6653.
      </li>

      <li style="font-family: 'Times New Roman'">
        Wang, K., He, B., & Zhu, W. P. TSTNN: Two-stage transformer based neural network for speech enhancement in the time domain. <em> ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing</em>. IEEE, 2021, pp. 7098-7102).
      </li>
    </ol>
  </div> -->

  <h3>Audio samples</h3>
  <p>
    <!-- Reference: <br/>
    <code>@article{}
    </code>
    <br/> -->
    We will demonstrate the benefit of the proposed method in the following two aspects:
    <ul>
      <li>First we show the improvement obtained by our proposed, speech enhancement agnostic method for phase estimation, compared to the fully synthetic phase retrieval proposed in [1];</li>
      <li>Secondly, we demonstrate the benefit of the proposed phase estimation applied on top of the speech enhancement approach.</li>
    </ul>

    All the noisy samples are normalised to -26 dBov individually based on the active speech level (ASL).<br/>
    We recommend using neutral sound headphone to better discern differences among the presented methods. 
 
  </p>
    
  </div>

  <h4>Using synthesised phase [1] vs the proposed reconstructed phase</h4>
  <div>
    Here we see the effect of using the synthetic phase retrived by the algorithm proposed in [1]. <br/>

    It may be observed that using the purely synthesised phase leads to an unnatural output, especially at high SNR, where the underlying signal phase is not heavily distorted by the noise. In comparison, our proposed method provides a more natural sounding output and the effect of the phase enhancement is perceivable especially in the voiced segments as having less "vocoding-like" artefacts. Since our method combines the predicted phase with that of the mixture signal, it helps preserve the naturalness when the underlying signal is less corrupted by noise. <br/>

  </div>
    
  <div>

    <table class="tb" id="samplesSyn">
      <thead>
      <tr>
        <th>Methods</th>
        <th>Noisy input</th>
        <th>Real CRUSE</th>
        <th>Real CRUSE-synthetic</th>
        <th>Real CRUSE-agnostic</th>
        <th>Clean ref</th>
      </tr>
      </thead>
    <tbody>
    </tbody>
	</table>
  </div>

  <br/>

  <h4>Improvement by the proposed phase reconstruction</h4>

    <div>

    Now, we demonstrate the benefit of using the estimated phase obtained from the proposed method. <br/>
    The samples below are processed by:
    <ul>
      <li><strong>Real CRUSE</strong>: CRUSE net [2] predicting a real-valued mask from the noisy magnitude;</li>
      <li><strong>Real CRUSE - agnostic</strong>: reconstructing phase based on the magnitude estimated by real CRUSE. The DNNs for phase gradient estimation are trained in an SE-Agnostic manner, i.e., on magnitudes of <em>clean speech</em>;</li>
      <li><strong>Real CRUSE - clean phase</strong>: combining the magnitude <em>estimated</em> by real CRUSE and the clean signal phase. We consider this the performance upper bound of phase reconstruction;</li>

      <li><strong>Complex CRUSE</strong>: CRUSE net [2] predicting a complex mask. To enable a complex mask prediction, the network takes the real- and imaginary-part of the noisy STFT as input and employs hyperbolic tangent function as the final activation function. Other parts of the network and the traning scheme are kept the same as in [2];</li>
      <li><strong>Complex CRUSE - agnostic</strong>: reconstructing phase based on the magnitude estimated by complex CRUSE. The DNNs for phase gradient estimation are trained in an SE-Agnostic manner, i.e., on magnitudes of <em>clean speech</em>;</li>
      <li><strong>Complex CRUSE - clean phase</strong>: combining the magnitude <em>estimated</em> by complex CRUSE and the clean signal phase.  We consider this the performance upper bound of phase reconstruction;</li>
      
    </ul>

    Note that the effect of the phase reconstruction is best perceivable as reduction of "vocoding-like" artefacts, which occur when noise is present between harmonics. This is also visible in the spectra. <br/>
    Obviously, if the initial phase estimate is good, less difference is be observed bewtween the speech estimate with the noisy phase and the one with the reconstructed phase. <br/>

    <p style="color:#003366; list-style-type:disc; font-size=8; font-style: italic;">
      For the ease of observation, we zoom all the spectrogram into <strong class='no-italics'>[0, 4] kHz</strong>. <br/>
      <em>By moving your mouse over the spectrogram of the proposed method, you can see the difference to using the noisy phase. </em><br/>
      Click the spectrogram to enlarge/reset it.
    </p>
    
  </div>
  
  <div>
    <!-- <p style="color:#003366; list-style-type:disc; font-size=8; font-style: italic;">
    Hover your mouse on the spectrogram to check the noisy input. <br/>
    Click the spectrogram to enlarge/reset it.
    </p>
   -->
    <table class="tb" id="samplesAgn">
      <thead>
      <tr>
        <th>Methods</th>
        <th>Noisy input</th>
        <th>Real CRUSE</th>
        <th>Real CRUSE - agnostic</th>
        <th>Real CRUSE - clean phase</th>
        <th>Complex CRUSE</th>
        <th>Complex CRUSE - agnostic</th>
        <th>Complex CRUSE - clean phase</th>
        <th>Clean ref</th>
      </tr>
      </thead>
    <tbody>
    </tbody>
  </table>
  </div>

<h4>References</h4>
<div style='font-size: 12;'>
  <ol>
    <!-- 1 -->
    <li style="font-family: 'Times New Roman'">
      Y. Masuyama, K. Yatabe, K. Nagatomo, and Y. Oikawa, "Online phase reconstruction via DNN-based phase differences estimation", <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, (2022), 31, 163-176.
    </li>
    
    <!-- 2 -->
    <li style="font-family: 'Times New Roman'">
      S. Braun, H. Gamper, C. K. Reddy, and I. Tashev, “Towards efficient models for real-time deep noise suppression,” <em>ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2021, pp. 656–660.
    </li>

  </ol>
</div>

<br/>

<script>

// Top button
//Get the button
var mybutton = document.getElementById("topBtn");

// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}

// show the noisy phase ver
function showNoisy(img) {
  img.src = img.src.replace('-agn-comb200', '');
}

// show the original
function showOriginal(img) {
  var end = img.src.split('_');
  var end = '_'+end[end.length-1];
  img.src = img.src.replace(end, img.method+'.png');
}

function enlargeImg(img) {
  if (img.className != 'enlarged'){
    // enlarge the image
    img.src = img.src.replace('_1noisy.png', img.method+'.png');
	img.className='enlarged';
  } else {
    // reset
    img.className='original';
  }
  // Animation effect
  img.style.transition = "transform 0.25s ease";
}

var methodsSyn = [
'_1noisy',
'_realCruse',
'_realCruse-syn',
'_realCruse-agn-comb200',
'_0clean'
];

var filenamesSyn = [
'cleanFileId1109_cafe_male_2_snr0dB',
'cleanFileId7964_cafe_snr5dB',
'cleanFileId8527_cafe_snr10dB',
'cleanFileId5164_traffic_male_2_snr5dB',
];

var infoSyn = [
'Cafe, SNR=2dB',
'Cafe, SNR=6dB',
'Cafe, SNR=10dB',
'Traffic, SNR=12dB',
];

const elementWidth = '250';

var tbody = document.getElementById("samplesSyn");
for (var i in filenamesSyn) {
    var tr = document.createElement('tr');   
    tbody.appendChild(tr);
    var td = document.createElement('td');
    td.align="center";
    td.innerHTML = infoSyn[i];
    tr.appendChild(td);
    for (var j in methodsSyn) {
      var td = document.createElement('td');
      td.width = elementWidth;
      tr.appendChild(td);
      var img = document.createElement("img");
      img.src = './img/'+filenamesSyn[i]+methodsSyn[j]+'.png';
      img.method = methodsSyn[j];
    //   img.onmouseover = function() {showNoisy(this)};
    //   img.onmouseout= function() {showOriginal(this)};
	    img.onclick = function () {enlargeImg(this)};
      img.width= elementWidth;
      td.appendChild(img);
      var audio = document.createElement("audio");
      audio.src ='./audio/'+filenamesSyn[i]+methodsSyn[j]+'.wav';
      audio.controls = true;
      td.appendChild(audio);
      audio.style.width = elementWidth;

    }
    
}

var methodsAgn = [
'_1noisy',
'_realCruse',
'_realCruse-agn-comb200',
'_realCruse-cleanPhs',
'_complexCruse',
'_complexCruse-agn-comb200',
'_complexCruse-cleanPhs',
'_0clean'
];

var filenamesAgn = [
// 'cleanFileId1109_cafe_male_1_snr0dB',
'cleanFileId1880_traffic_snr0dB', //female_1_
'cleanFileId1109_cafe_snr0dB', //_male_2
// 'cleanFileId1109_cafe_female_1_snr0dB',
// 'cleanFileId1880_traffic_female_2_snr0dB',
'cleanFileId1042_cafe_snr5dB', //male_1_
// 'cleanFileId1042_cafe_male_2_snr5dB',
// 'cleanFileId3656_traffic_male_1_snr5dB',
'cleanFileId5164_traffic_snr5dB', //_male_1
// 'cleanFileId5164_traffic_male_2_snr5dB',
// 'cleanFileId3656_traffic_female_1_snr5dB',
// 'cleanFileId546_cafe_male_1_snr10dB',
// 'cleanFileId546_cafe_female_1_snr10dB',
'cleanFileId546_cafe_snr10dB', //_female_2
];

var infoAgn = [
// 'Cafe, SNR=0, #1',
'Traffic, SNR=0dB',
'Cafe, SNR=2dB',
// 'Cafe, SNR=0, #3',
// 'Traffic, SNR=0, #2',
'Cafe, SNR=8dB',
// 'Cafe, SNR=5, #2',
// 'Traffic, SNR=5, #1',
'Traffic, SNR=10dB',
// 'Traffic, SNR=5, #3',
// 'Traffic, SNR=5, #4',
// 'Cafe, SNR=10, #1',
// 'Cafe, SNR=10, #2',
'Cafe, SNR=12dB',
];

const elementWidthSmall = '210';

var tbody = document.getElementById("samplesAgn");
for (var i in filenamesAgn) {
    var tr = document.createElement('tr');   
    tbody.appendChild(tr);
    var td = document.createElement('td');
    td.align="center";
    td.innerHTML = infoAgn[i];
    tr.appendChild(td);
    for (var j in methodsAgn) {
      var td = document.createElement('td');
      td.width = elementWidthSmall;
      tr.appendChild(td);

      img = document.createElement("img");
      img.src = './img/'+filenamesAgn[i]+methodsAgn[j]+'.png';
      img.method = methodsAgn[j];
      if (methodsAgn[j].includes("agn")){
        img.onmouseover = function() {showNoisy(this)};
        img.onmouseout= function() {showOriginal(this)};
      }
        img.onclick = function () {enlargeImg(this)};
      img.width= elementWidthSmall;
      td.appendChild(img);

      var audio = document.createElement("audio");
      audio.src ='./audio/'+filenamesAgn[i]+methodsAgn[j]+'.wav';
      audio.controls = true;
      td.appendChild(audio);
      audio.style.width = elementWidthSmall;

    }
    
}

</script>

</body>
